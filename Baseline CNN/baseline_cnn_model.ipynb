{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from time import sleep\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holiday_triples(dat):\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!GET TRIPLES CALLED!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        image_groups = {}\n",
    "        counter = 50000\n",
    "        for index, row in dat.iterrows():\n",
    "            img_name = row['new_filename']\n",
    "            group_name = row['artist']\n",
    "            if group_name in image_groups:\n",
    "                image_groups[group_name].append(img_name)\n",
    "            else:\n",
    "                image_groups[group_name] = [img_name]\n",
    "            counter = counter - 1\n",
    "            if counter == 0:\n",
    "                break\n",
    "            \n",
    "        num_sims = 0\n",
    "        image_triples = []\n",
    "        group_list = sorted(list(image_groups.keys()))\n",
    "        for i, g in enumerate(group_list):\n",
    "                if num_sims % 100 == 0:\n",
    "                        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                                    .format(num_sims, num_sims, 2*num_sims))\n",
    "                images_in_group = image_groups[g]\n",
    "                sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "                # for each similar pair, generate a corresponding different pair\n",
    "                for ref_image, sim_image in sim_pairs_it:\n",
    "                        image_triples.append((ref_image, sim_image, 1))\n",
    "                        num_sims += 1\n",
    "                        while True:\n",
    "                                j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "                                if j != i:\n",
    "                                        break\n",
    "                        dif_image_candidates = image_groups[group_list[j]]\n",
    "                        k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "                        dif_image = dif_image_candidates[k]\n",
    "                        image_triples.append((ref_image, dif_image, 0))\n",
    "        print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                    .format(num_sims, num_sims, 2*num_sims))\n",
    "        return image_triples\n",
    "\n",
    "def train_test_split(triples, splits):\n",
    "        assert sum(splits) == 1.0\n",
    "        split_pts = np.cumsum(np.array([0.] + splits))\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        shuffled_triples = [triples[i] for i in indices]\n",
    "        data_splits = []\n",
    "        for sid in range(len(splits)):\n",
    "                start = int(split_pts[sid] * len(triples))\n",
    "                end = int(split_pts[sid + 1] * len(triples))\n",
    "                data_splits.append(shuffled_triples[start:end])\n",
    "        return data_splits\n",
    "\n",
    "def get_image_data(image_name, folder):\n",
    "    \n",
    "    img_dir = \"/home/lr_navin/Painter_Siamese/dataset/\" + str(folder) + \"/\" + str(folder) + \"/\" \n",
    "    img = image.load_img(img_dir + image_name, target_size=(img_rows, img_cols))\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)[0].transpose()\n",
    "\n",
    "    return x\n",
    "\n",
    "def batch_to_vectors(batch, vec_size):\n",
    "        # Data Prep from Image - Feed to CNN\n",
    "        img_colours, img_rows, img_cols = input_dim\n",
    "        \n",
    "        X1 = np.zeros((len(batch), img_colours, img_rows, img_cols))\n",
    "        X2 = np.zeros((len(batch), img_colours, img_rows, img_cols))\n",
    "\n",
    "        Y = np.zeros((len(batch), 2))\n",
    "       \n",
    "        for tid in range(len(batch)):\n",
    "            \n",
    "            split_1 = batch[tid][0].split('/')\n",
    "            split_2 = batch[tid][1].split('/')\n",
    "\n",
    "            X1[tid] = get_image_data(split_1[1], split_1[0])#vec_dict[name_1].reshape(vec_size)\n",
    "            X2[tid] = get_image_data(split_2[1], split_2[0])#vec_dict[name_2].reshape(vec_size)\n",
    "            Y[tid] = [1, 0] if batch[tid][2] == 0 else [0, 1]\n",
    "        \n",
    "        return ([X1, X2], Y)\n",
    "        \n",
    "def data_generator(triples, vec_size, batch_size=32, stamp_str = \"None\"):\n",
    "#         print(stamp_str)\n",
    "#         print(\"Data Gen----\")\n",
    "        while True:\n",
    "            # shuffle once per batch\n",
    "            indices = np.random.permutation(np.arange(len(triples)))\n",
    "            num_batches = len(triples) // batch_size\n",
    "            for bid in range(num_batches):\n",
    "                batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "                batch = [triples[i] for i in batch_indices]\n",
    "                yield batch_to_vectors(batch, vec_size)\n",
    "\n",
    "def evaluate_model(model_file, test_gen):\n",
    "        model_name = os.path.basename(model_file)\n",
    "        model = load_model(model_file, custom_objects={'contrastive_loss': contrastive_loss})\n",
    "        print(\"=== Evaluating model: {:s} ===\".format(model_name))\n",
    "        ytrue, ypred = [], []\n",
    "        num_test_steps = len(test_gen) // BATCH_SIZE\n",
    "        for i in range(num_test_steps):\n",
    "                (X1, X2), Y = next(test_gen)\n",
    "                Y_ = model.predict([X1, X2])\n",
    "                ytrue.extend(np.argmax(Y, axis=1).tolist())\n",
    "                ypred.extend(np.argmax(Y_, axis=1).tolist())\n",
    "        accuracy = accuracy_score(ytrue, ypred)\n",
    "        print(\"\\nAccuracy: {:.3f}\".format(accuracy))\n",
    "        print(\"\\nConfusion Matrix\")\n",
    "        print(confusion_matrix(ytrue, ypred))\n",
    "        print(\"\\nClassification Report\")\n",
    "        print(classification_report(ytrue, ypred))\n",
    "        return accuracy\n",
    "\n",
    "def get_model_file(data_dir, vector_name, merge_mode, borf):\n",
    "        return os.path.join(data_dir, \"models\", \"{:s}-{:s}-{:s}.h5\"\n",
    "                                                .format(vector_name, merge_mode, borf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drive_1 = '/home/lr_navin/Painter_Siamese/'\n",
    "\n",
    "img_dir = '/home/lr_navin/Painter_Siamese/dataset/train/train/'\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "\n",
    "COMPLEX = 1\n",
    "W_INIT = 'he_normal'\n",
    "L2_REG = 0.003\n",
    "VECTORIZERS = [\"InceptionV3\"]\n",
    "MERGE_MODES = [\"Concat\", \"Euclidean\"]\n",
    "input_dim = (3, img_rows, img_cols)\n",
    "BATCH_SIZE = 25\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "PENULTIMATE_SIZE = 2048\n",
    "SOFTMAX_SIZE = 1584\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN Network\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "\n",
    "    # input image dimensions\n",
    "    img_colours, img_rows, img_cols = input_dim\n",
    "    \n",
    "    # number of convolutional filters to use\n",
    "    nb_filters = 16\n",
    "    # size of pooling area for max pooling\n",
    "    nb_pool = 2\n",
    "    # convolution kernel size\n",
    "    nb_conv = 3\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (nb_conv, nb_conv),\n",
    "                     padding='same',\n",
    "                     input_shape=(img_colours, img_rows, img_cols),\n",
    "                     kernel_initializer=W_INIT,\n",
    "                     kernel_regularizer=l2(l=L2_REG)))\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(nb_filters, (nb_conv, nb_conv),\n",
    "                     padding='same',\n",
    "                     kernel_initializer=W_INIT,\n",
    "                     kernel_regularizer=l2(l=L2_REG)))    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool), data_format=\"channels_first\"))\n",
    "    model.add(Dropout(rate=0.5)) #0.25 #too much dropout and loss -> nan\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, input_shape=(input_dim,), activation='relu'))\n",
    "    #model.add(Dropout(0.05)) #too much dropout and loss -> nan\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dense(2, activation='relu'))\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex Network Try\n",
    "\n",
    "def siamese_cnn(imgs_dim, compile_):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(_convolutional_layer(nb_filter=16, input_shape=imgs_dim))\n",
    "    model.add(BatchNormalization(axis=-1, input_shape=imgs_dim))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=16))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)))\n",
    "\n",
    "    model.add(_convolutional_layer(nb_filter=32))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=32))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=32))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)))\n",
    "\n",
    "    model.add(_convolutional_layer(nb_filter=64))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=64))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=64))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)))\n",
    "\n",
    "    model.add(_convolutional_layer(nb_filter=128))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=128))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=128))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)))\n",
    "\n",
    "    model.add(_convolutional_layer(nb_filter=256))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=256))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(_convolutional_layer(nb_filter=256))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    model.add(MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(_dense_layer(output_dim=PENULTIMATE_SIZE))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(PReLU(alpha_initializer=W_INIT))\n",
    "    \n",
    "    model.add(_dense_layer(output_dim=1024))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(_dense_layer(output_dim=1024))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(_dense_layer(output_dim=1024))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(_dense_layer(output_dim=512))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(_dense_layer(output_dim=512))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(_dense_layer(output_dim=128))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(_dense_layer(output_dim=128))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "#     model.add(_dense_layer(output_dim=2))\n",
    "#     model.add(Activation(\"softmax\"))\n",
    "\n",
    "    if compile_:\n",
    "        model.add(Dropout(rate=0.5))\n",
    "        model.add(_dense_layer(output_dim=SOFTMAX_SIZE))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(Activation(activation='softmax'))\n",
    "        return compile_model(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _convolutional_layer(nb_filter, input_shape=None):\n",
    "    if input_shape:\n",
    "        return _first_convolutional_layer(nb_filter, input_shape)\n",
    "    else:\n",
    "        return _intermediate_convolutional_layer(nb_filter)\n",
    "\n",
    "\n",
    "def _first_convolutional_layer(nb_filter, input_shape):\n",
    "    return Conv2D(\n",
    "        nb_filter, (3, 3), input_shape=input_shape,\n",
    "        padding='same', kernel_initializer=W_INIT, kernel_regularizer=l2(l=L2_REG))\n",
    "\n",
    "\n",
    "def _intermediate_convolutional_layer(nb_filter):\n",
    "    return Conv2D(\n",
    "        nb_filter, (3, 3), padding='same',\n",
    "        kernel_initializer=W_INIT, kernel_regularizer=l2(l=L2_REG))\n",
    "\n",
    "\n",
    "def _dense_layer(output_dim):\n",
    "    return Dense(units=output_dim, kernel_regularizer=l2(l=L2_REG), kernel_initializer=W_INIT)\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=adam,\n",
    "        metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size - 79433\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!GET TRIPLES CALLED!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 127000 pos + 127000 neg = 254000 total image triples\n",
      "Generated 539100 pos + 539100 neg = 1078200 total image triples\n",
      "Generated 592800 pos + 592800 neg = 1185600 total image triples\n",
      "Generated 862300 pos + 862300 neg = 1724600 total image triples\n",
      "Generated 862300 pos + 862300 neg = 1724600 total image triples\n",
      "Generated 1141000 pos + 1141000 neg = 2282000 total image triples\n",
      "Generated 1484400 pos + 1484400 neg = 2968800 total image triples\n",
      "Generated 2527300 pos + 2527300 neg = 5054600 total image triples\n",
      "Generated 3540900 pos + 3540900 neg = 7081800 total image triples\n",
      "Generated 3695207 pos + 3695207 neg = 7390414 total image triples\n",
      "6651372 739042\n"
     ]
    }
   ],
   "source": [
    "# Data Prep \n",
    "scores = np.zeros((len(VECTORIZERS), len(MERGE_MODES)))\n",
    "\n",
    "dat = pd.read_csv('/home/lr_navin/Painter_Siamese/train_info_custom.csv')\n",
    "print(\"Train Data Size - \" + str(len(dat)))\n",
    "\n",
    "\n",
    "image_sets = get_holiday_triples(dat)\n",
    "\n",
    "train_triples, val_triples = train_test_split(image_sets, splits=[0.9, 0.1])\n",
    "print(len(train_triples), len(val_triples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Data - For NN\n",
    "\n",
    "train_gen = data_generator(train_triples, input_dim, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, input_dim, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Type ---- 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 3, 256, 256)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 3, 256, 256)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 128)          13351872    input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128)          0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 13,351,872\n",
      "Trainable params: 13,344,832\n",
      "Non-trainable params: 7,040\n",
      "__________________________________________________________________________________________________\n",
      "concatnated model\n",
      "STEPS INFO - 266054 AND 29561\n",
      "Epoch 1/10\n",
      "    70/266054 [..............................] - ETA: 36:20:11 - loss: 346.2245 - acc: 0.5069"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-219f8e4dae43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                               callbacks=[checkpoint])\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mfinal_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_drive_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inceptionv3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################\n",
    "######### Simple CNN Model #########\n",
    "####################################\n",
    "\n",
    "# network definition\n",
    "#base_network = create_base_network(input_dim)\n",
    "print(\"Network Type ---- \" + str(COMPLEX))\n",
    "if COMPLEX == 1:\n",
    "    base_network = siamese_cnn(input_dim, compile_=False)\n",
    "else:\n",
    "    base_network = create_base_network(input_dim)\n",
    "\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "\n",
    "#keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "adam = Adam(lr=.001)\n",
    "if COMPLEX == 1:\n",
    "    model.compile(optimizer=adam, loss=contrastive_loss, metrics=[\"accuracy\"])\n",
    "else:\n",
    "    model.compile(optimizer=adam, loss=contrastive_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "print('concatnated model')\n",
    "best_model_name = get_model_file(data_drive_1, \"inceptionv3\", \"cat\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "print(\"STEPS INFO - \" + str(train_steps_per_epoch) + \" AND \" + str(val_steps_per_epoch)) \n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "final_model_name = get_model_file(data_drive_1, \"inceptionv3\", \"cat\", \"final\")\n",
    "model.save(final_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!GET TRIPLES CALLED!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 5500 pos + 5500 neg = 11000 total image triples\n",
      "Generated 36900 pos + 36900 neg = 73800 total image triples\n",
      "Generated 121600 pos + 121600 neg = 243200 total image triples\n",
      "Generated 158700 pos + 158700 neg = 317400 total image triples\n",
      "Generated 159600 pos + 159600 neg = 319200 total image triples\n",
      "Generated 253900 pos + 253900 neg = 507800 total image triples\n",
      "Generated 284800 pos + 284800 neg = 569600 total image triples\n",
      "Generated 326200 pos + 326200 neg = 652400 total image triples\n",
      "Generated 342600 pos + 342600 neg = 685200 total image triples\n",
      "Generated 342600 pos + 342600 neg = 685200 total image triples\n",
      "Generated 396000 pos + 396000 neg = 792000 total image triples\n",
      "Generated 417700 pos + 417700 neg = 835400 total image triples\n",
      "Generated 460100 pos + 460100 neg = 920200 total image triples\n",
      "Generated 503347 pos + 503347 neg = 1006694 total image triples\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!GET TRIPLES CALLED!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 65921 pos + 65921 neg = 131842 total image triples\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!GET TRIPLES CALLED!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "Generated 118000 pos + 118000 neg = 236000 total image triples\n",
      "Generated 135400 pos + 135400 neg = 270800 total image triples\n",
      "Generated 179200 pos + 179200 neg = 358400 total image triples\n",
      "Generated 209700 pos + 209700 neg = 419400 total image triples\n",
      "Generated 209700 pos + 209700 neg = 419400 total image triples\n",
      "Generated 292200 pos + 292200 neg = 584400 total image triples\n",
      "Generated 316900 pos + 316900 neg = 633800 total image triples\n",
      "Generated 346400 pos + 346400 neg = 692800 total image triples\n",
      "Generated 511100 pos + 511100 neg = 1022200 total image triples\n",
      "Generated 569270 pos + 569270 neg = 1138540 total image triples\n",
      "WARNING:tensorflow:From /home/lr_navin/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lr_navin/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/lr_navin/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "=== Evaluating model: inceptionv3-cat-best.h5 ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8fc7ccd7d1fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Best Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Seen Classes Model -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mfinal_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_triples_seen_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# UnSeen Classes Model -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6aa8710b6a0e>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_file, test_gen)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Evaluating model: {:s} ===\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mytrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mnum_test_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "def data_generator(triples, vec_size, vec_dict, batch_size):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size: (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            yield batch_to_vectors(batch, vec_size, vec_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Best Model\n",
    "best_model_name = get_model_file(data_drive_1, \"inceptionv3\", \"cat\", \"best\")\n",
    "# Final Model\n",
    "final_model_name = get_model_file(data_drive_1, \"inceptionv3\", \"cat\", \"final\")\n",
    "\n",
    "\n",
    "test_data_seen = pd.read_csv('/home/lr_navin/Painter_Siamese/Evaluate_Baseline/info_data/test-train_test.csv')\n",
    "test_data_unseen = pd.read_csv('/home/lr_navin/Painter_Siamese/Evaluate_Baseline/info_data/test_info-test_only.csv')\n",
    "test_data_mix = pd.read_csv('/home/lr_navin/Painter_Siamese/Evaluate_Baseline/info_data/test_info.csv')\n",
    "\n",
    "test_triples_seen = get_holiday_triples(test_data_seen)\n",
    "test_triples_unseen = get_holiday_triples(test_data_unseen)\n",
    "test_triples_mix = get_holiday_triples(test_data_mix)\n",
    "\n",
    "# Testing Model's Performance - 3 types of test datasets\n",
    "test_triples_seen_gen   = data_generator(test_triples_seen, input_dim, BATCH_SIZE)\n",
    "test_triples_unseen_gen = data_generator(test_triples_unseen, input_dim, BATCH_SIZE)\n",
    "test_triples_mix_gen    = data_generator(test_triples_mix, input_dim, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Best Model\n",
    "# Seen Classes Model - \n",
    "final_accuracy = evaluate_model(best_model_name, test_triples_seen_gen)\n",
    "\n",
    "# UnSeen Classes Model - \n",
    "final_accuracy = evaluate_model(best_model_name, test_triples_unseen_gen)\n",
    "\n",
    "# Mix Classes Model - \n",
    "final_accuracy = evaluate_model(best_model_name, test_triples_mix_gen)\n",
    "\n",
    "\n",
    "# Final Model\n",
    "# Seen Classes Model - \n",
    "final_accuracy = evaluate_model(final_model_name, test_triples_seen_gen)\n",
    "\n",
    "# UnSeen Classes Model - \n",
    "final_accuracy = evaluate_model(final_model_name, test_triples_unseen_gen)\n",
    "\n",
    "# Mix Classes Model - \n",
    "final_accuracy = evaluate_model(final_model_name, test_triples_mix_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
