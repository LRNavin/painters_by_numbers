{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction - Pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "##image bomb? \n",
    "from PIL.Image import LANCZOS\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 1000000000                                                                                              \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Directory - Make it cloud suitable\n",
    "train_img_dir = \"/home/lr_navin/Painter_Siamese/dataset/train/train/\"\n",
    "test_img_dir = \"/home/lr_navin/Painter_Siamese/dataset/test/test/\"\n",
    "\n",
    "dirs_array = np.array([train_img_dir, test_img_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Model Gen\n",
    "# model = VGG19(weights='imagenet',include_top=False,pooling='avg')\n",
    "# model = InceptionV3(weights='imagenet',include_top=False,pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vectors generated\n",
      "100 vectors generated\n",
      "200 vectors generated\n",
      "300 vectors generated\n",
      "400 vectors generated\n",
      "500 vectors generated\n",
      "600 vectors generated\n",
      "700 vectors generated\n",
      "800 vectors generated\n",
      "900 vectors generated\n",
      "1000 vectors generated\n",
      "1100 vectors generated\n",
      "1200 vectors generated\n",
      "1300 vectors generated\n",
      "1400 vectors generated\n",
      "1500 vectors generated\n",
      "1600 vectors generated\n",
      "1700 vectors generated\n",
      "1800 vectors generated\n",
      "1900 vectors generated\n",
      "2000 vectors generated\n",
      "2100 vectors generated\n",
      "2200 vectors generated\n",
      "2300 vectors generated\n",
      "2400 vectors generated\n",
      "2500 vectors generated\n",
      "2600 vectors generated\n",
      "2700 vectors generated\n",
      "2800 vectors generated\n",
      "2900 vectors generated\n",
      "3000 vectors generated\n",
      "3100 vectors generated\n",
      "3200 vectors generated\n",
      "3300 vectors generated\n",
      "3400 vectors generated\n",
      "3500 vectors generated\n",
      "3600 vectors generated\n",
      "3700 vectors generated\n",
      "3800 vectors generated\n",
      "3900 vectors generated\n",
      "4000 vectors generated\n",
      "4100 vectors generated\n",
      "4200 vectors generated\n",
      "4300 vectors generated\n",
      "4400 vectors generated\n",
      "4500 vectors generated\n",
      "4600 vectors generated\n",
      "4700 vectors generated\n",
      "4800 vectors generated\n",
      "4900 vectors generated\n",
      "5000 vectors generated\n",
      "5100 vectors generated\n",
      "5200 vectors generated\n",
      "5300 vectors generated\n",
      "5400 vectors generated\n",
      "5500 vectors generated\n",
      "5600 vectors generated\n",
      "5700 vectors generated\n",
      "5800 vectors generated\n",
      "5900 vectors generated\n",
      "6000 vectors generated\n",
      "6100 vectors generated\n",
      "6200 vectors generated\n",
      "6300 vectors generated\n",
      "6400 vectors generated\n",
      "6500 vectors generated\n",
      "6600 vectors generated\n",
      "6700 vectors generated\n",
      "6800 vectors generated\n",
      "6900 vectors generated\n",
      "7000 vectors generated\n",
      "7100 vectors generated\n",
      "7200 vectors generated\n",
      "7300 vectors generated\n",
      "7400 vectors generated\n",
      "7500 vectors generated\n",
      "7600 vectors generated\n",
      "7700 vectors generated\n",
      "7800 vectors generated\n",
      "7900 vectors generated\n",
      "8000 vectors generated\n",
      "8100 vectors generated\n",
      "8200 vectors generated\n",
      "8300 vectors generated\n",
      "8400 vectors generated\n",
      "8500 vectors generated\n",
      "8600 vectors generated\n",
      "8700 vectors generated\n",
      "8800 vectors generated\n",
      "8900 vectors generated\n",
      "9000 vectors generated\n",
      "9100 vectors generated\n",
      "9200 vectors generated\n",
      "9300 vectors generated\n",
      "9400 vectors generated\n",
      "9500 vectors generated\n",
      "9600 vectors generated\n",
      "9700 vectors generated\n",
      "9800 vectors generated\n",
      "9900 vectors generated\n",
      "10000 vectors generated\n",
      "10100 vectors generated\n",
      "10200 vectors generated\n",
      "10300 vectors generated\n",
      "10400 vectors generated\n",
      "10500 vectors generated\n",
      "10600 vectors generated\n",
      "10700 vectors generated\n",
      "10800 vectors generated\n",
      "10900 vectors generated\n",
      "11000 vectors generated\n",
      "11100 vectors generated\n",
      "11200 vectors generated\n",
      "11300 vectors generated\n",
      "11400 vectors generated\n",
      "11500 vectors generated\n",
      "11600 vectors generated\n",
      "11700 vectors generated\n",
      "11800 vectors generated\n",
      "11900 vectors generated\n",
      "12000 vectors generated\n",
      "12100 vectors generated\n",
      "12200 vectors generated\n",
      "12300 vectors generated\n",
      "12400 vectors generated\n",
      "12500 vectors generated\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7907245393e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#         print(image_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mfvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:s}\\t{:s}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mnum_vecs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# Feature Extract and store in \n",
    "fvec = open('image_for_cnn.tsv', \"w\")\n",
    "num_vecs = 0 \n",
    "\n",
    "counter = 0\n",
    "\n",
    "for img_dir in dirs_array:\n",
    "    for image_ in os.listdir(img_dir):\n",
    "        img = image.load_img(img_dir+image_, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)[0].transpose()\n",
    "#         print(x.shape)\n",
    "        features = x.flatten() #model.predict(x)[0]\n",
    "#         print(len(features))\n",
    "#         if np.array_equal(features.reshape(3, 224, 224,), x):\n",
    "#             print('True')\n",
    "        # convert from Numpy to a list of values\n",
    "        #features_arr = np.char.mod('%f', features)\n",
    "\n",
    "        if num_vecs % 100 == 0:\n",
    "            print(\"{:d} vectors generated\".format(num_vecs))\n",
    "\n",
    "        image_vector = \",\".join([\"{:.5e}\".format(v) for v in features.tolist()])\n",
    "        \n",
    "#         print(image_)\n",
    "        fvec.write(\"{:s}\\t{:s}\\n\".format(image_, image_vector))\n",
    "        \n",
    "        num_vecs += 1\n",
    "        counter += 1\n",
    "#         if counter == 100:\n",
    "#             break\n",
    "            \n",
    "    counter = 0\n",
    "fvec.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SMALL = 0\n",
    "\n",
    "if RUN_SMALL:\n",
    "    dat_all = pd.read_csv('/home/lr_navin/Painter_Siamese/all_data_info_custom-copy.csv')\n",
    "    test_all = '/home/lr_navin/Painter_Siamese/image_for_cnn.tsv'\n",
    "\n",
    "    fvec = open(test_all, \"r\")\n",
    "\n",
    "    img_array = []\n",
    "    for row in fvec:\n",
    "        image_name, dum = row.strip().split(\"\\t\")\n",
    "        img_array.append(\"train/\" + image_name)\n",
    "\n",
    "    # print(list(dat_all.index.values))\n",
    "\n",
    "    fvec = open('small_info.tsv', \"w\")\n",
    "\n",
    "    index_array=[]\n",
    "    for index, row in dat_all.iterrows():\n",
    "        img = row['new_filename']\n",
    "\n",
    "        for im_ in img_array:\n",
    "            if im_ == img:\n",
    "                print(\"Found - \" + str(img))\n",
    "                index_array.append(index)\n",
    "\n",
    "    small_data = dat_all.loc[index_array]\n",
    "    small_data.to_csv('small_info.tsv')\n",
    "\n",
    "\n",
    "    fvec.close()            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
